base_config:
  - ./base_task.yaml
  - ../datasets/svs/csd/preprocess.yaml 
task_cls: tasks.visinger.VISingerTask
################################################
# Model
################################################
hidden_size: 192
p_dropout: 0.1
encoder_type: rel_fft  # fft|ffn|rel_fft

# FFT encoder
enc_layers: 6
ffn_kernel_size: 9
ffn_filter_channels: 768  # hidden_size * 4
enc_prenet: true
enc_pre_ln: true
num_heads: 2
ffn_act: gelu
use_pos_embed: true

# Waveform Decoder
dec_blocks: "1"
dec_kernel_size: [3,7,11]
dec_dilation_sizes: [[1,3,5], [1,3,5], [1,3,5]]
upsample_rates: [5,5,3,2,2]  # for compute 300 hop-size
initial_upsample_channels: 512
upsample_kernel_sizes: [11,11,7,4,4]  # for compute 300 hop-size
gin_channels: 256

# Prior encoder
use_pitch_encoder: true
frame_prior_layers: 4

# Pitch predictor
use_pitch_embed: true
pitch_predictor_layers: 6
pitch_predictor_kernel_size: 9
pitch_type: frame

# Phoneme predictor
use_phoneme_pred: true
phoneme_predictor_layers: 2

# Discriminator
use_spectral_norm: false
disc_win_num: 3
mel_disc_hidden_size: 256
disc_norm: in
disc_reduction: stack
disc_interval: 1
disc_start_steps: 0

# mel loss
mel_losses: l1:45.0

# Loss lambda
lambda_pitch: 10.0
lambda_ctc: 45.0
lambda_mel_adv: 1.0
lambda_kl: 1.0
lambda_fm: 2.0
kl_start_steps: 1
kl_min: 0.0
posterior_start_steps: 0
predictor_grad: 0.1

################################################
# Optimization
################################################
optimizer: AdamW
lr: 0.0002
scheduler: steplr
optimizer_adam_beta1: 0.8
optimizer_adam_beta2: 0.99
eps: 1.0e-9
generator_scheduler_params:
  gamma: 0.999875
discriminator_scheduler_params:
  gamma: 0.999875
discriminator_optimizer_params:
  eps: 1.0e-09
  weight_decay: 0.0
weight_decay: 0.001
clip_grad_norm: 1
clip_grad_value: 0

################################################
# Train and evaluate
################################################
use_pesq: true
segment_size: 32
max_frames: 1280  # max sequence sizes
max_sentences: 4  # max batch size ( 16 * 4 = 64 )
max_updates: 600000
max_tokens: 60000
tb_log_interval: 100
val_check_interval: 1000
ckpt_save_interval: 1000
eval_max_batches: 50

####################
# Datasets
####################
ds_workers: 0
endless_ds: false  # If want to use exponentialLR with decay, should be `false` here